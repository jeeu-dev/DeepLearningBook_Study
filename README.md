# DeepLearningBook
-------
> Big Leader Study 
> Reference : [Deep Learning Book](http://www.deeplearningbook.org/) <br>

### Contents
#### 1 Introduction
~~1.1 Who Should Read This Book? <br>
~~1.2 Historical Trends in Deep Learning <br>

## I Applied Math and Machine Learning Basics

#### 2 Linear Algebra 292.1 Scalars, Vectors, Matrices and Tensors
~~2.2 Multiplying Matrices and Vectors ~~<br>
~~2.3 Identity and Inverse Matrices ~~<br>
~~2.4 Linear Dependence and Span ~~<br>
~~2.5 Norms ~~<br>
~~2.6 Special Kinds of Matrices and Vectors ~~<br>
~~2.7 Eigendecomposition ~~<br>
~~2.8 Singular Value Decomposition ~~<br>
~~2.9 The Moore-Penrose Pseudoinverse ~~<br>
~~2.10 The Trace Operator ~~<br>
~~2.11 The Determinant ~~<br>
~~2.12 Example: Principal Components Analysis ~~<br>

#### 3 Probability and Information Theory
~~3.1 Why Probability? ~~<br>
~~3.2 Random Variables ~~<br>
~~3.3 Probability Distributions ~~<br>
~~3.4 Marginal Probability ~~<br>
~~3.5 Conditional Probability ~~<br>
~~3.6 The Chain Rule of Conditional Probabilities ~~<br>
~~3.7 Independence and Conditional Independence ~~<br>
~~3.8 Expectation, Variance and Covariance ~~<br>
~~3.9 Common Probability Distributions ~~<br>
~~3.10 Useful Properties of Common Functions ~~<br>
~~3.11 Bayes' Rule ~~<br>
~~3.12 Technical Details of Continuous Variables ~~<br>
~~3.13 Information Theory ~~<br>
~~3.14 Structured Probabilistic Models ~~<br>

#### 4 Numerical Computation
~~4.1 Overﬂow and Underﬂow ~~<br>
~~4.2 Poor Conditioning ~~<br>
~~4.3 Gradient-Based Optimization ~~<br>
~~4.4 Constrained Optimization ~~<br>
~~4.5 Example: Linear Least Squares ~~<br>

#### 5 Machine Learning Basics 
~~5.1 Learning Algorithms ~~<br>
~~5.2 Capacity, Overﬁtting and Underﬁtting ~~<br>
~~5.3 Hyperparameters and Validation Sets ~~<br>
~~5.4 Estimators, Bias and Variance ~~<br>
~~5.5 Maximum Likelihood Estimation ~~<br>
~~5.6 Bayesian Statistics ~~<br>
~~5.7 Supervised Learning Algorithms ~~<br>
~~5.8 Unsupervised Learning Algorithms ~~<br>
~~5.9 Stochastic Gradient Descent ~~<br>
~~5.10 Building a Machine Learning Algorithm ~~<br>
~~5.11 Challenges Motivating Deep Learning ~~<br>

## II Deep Networks: Modern Practices 

#### 6 Deep Feedforward Networks 
~~6.1 Example: Learning XOR ~~<br>
~~6.2 Gradient-Based Learning ~~<br>
~~6.3 Hidden Units ~~<br>
~~6.4 Architecture Design ~~<br>
~~6.5 Back-Propagation and Other DiﬀerentiationAlgorithms ~~<br>
~~6.6 Historical Notes ~~<br>

#### 7 Regularization for Deep Learning
~~7.1 Parameter Norm Penalties ~~<br>
~~7.2 Norm Penalties as Constrained Optimization ~~<br>
~~7.3 Regularization and Under-Constrained Problems ~~<br>
~~7.4 Dataset Augmentation ~~<br>
~~7.5 Noise Robustness ~~<br>
~~7.6 Semi-Supervised Learning ~~<br>
~~7.7 Multitask Learning ~~<br>
~~7.8 Early Stopping ~~<br>
~~7.9 Parameter Tying and Parameter Sharing ~~<br>
~~7.10 Sparse Representations ~~<br>
~~7.11 Bagging and Other Ensemble Methods ~~<br>
~~7.12 Dropout ~~<br>
~~7.13 Adversarial Training ~~<br>
~~7.14 Tangent Distance, Tangent Prop and ManifoldTangent Classiﬁer ~~<br>

#### 8 Optimization for Training Deep Models
~~8.1 How Learning Diﬀers from Pure Optimization ~~<br>
~~8.2 Challenges in Neural Network Optimization ~~<br>
~~8.3 Basic Algorithms ~~<br>
~~8.4 Parameter Initialization Strategies ~~<br>
~~8.5 Algorithms with Adaptive Learning Rates ~~<br>
~~8.6 Approximate Second-Order Methods ~~<br>
~~8.7 Optimization Strategies and Meta-Algorithms ~~<br>

#### 9 Convolutional Networks 3269.1 The Convolution Operation
~~9.2 Motivation ~~<br>
~~9.3 Pooling ~~<br>
~~9.4 Convolution and Pooling as an Inﬁnitely Strong Prior ~~<br>
~~9.5 Variants of the Basic Convolution Function ~~<br>
~~9.6 Structured Outputs ~~<br>
~~9.7 Data Types ~~<br>
~~9.8 Eﬃcient Convolution Algorithms ~~<br>
~~9.9 Random or Unsupervised Features ~~<br>
~~9.10 The Neuroscientiﬁc Basis for ConvolutionalNetworks ~~<br>
~~9.11 Convolutional Networks and the History of Deep Learning ~~<br>

#### 10 Sequence Modeling: Recurrent and Recursive Nets
~~10.1 Unfolding Computational Graphs ~~<br>
~~10.2 Recurrent Neural Networks ~~<br>
~~10.3 Bidirectional RNNs ~~<br>
~~10.4 Encoder-Decoder Sequence-to-SequenceArchitectures ~~<br>
~~10.5 Deep Recurrent Networks ~~<br>
~~10.6 Recursive Neural Networks ~~<br>
~~10.7 The Challenge of Long-Term Dependencies ~~<br>
~~10.8 Echo State Networks ~~<br>
~~10.9 Leaky Units and Other Strategies for MultipleTime Scales ~~<br>
~~10.10 The Long Short-Term Memory and Other Gated RNNs ~~<br>
~~10.11 Optimization for Long-Term Dependencies ~~<br>
~~10.12 Explicit Memory ~~<br>

#### 11 Practical Methodology
~~11.1 Performance Metrics ~~<br>
~~11.2 Default Baseline Models ~~<br>
~~11.3 Determining Whether to Gather More Data ~~<br>
~~11.4 Selecting Hyperparameters ~~<br>
~~11.5 Debugging Strategies ~~<br>
~~11.6 Example: Multi-Digit Number Recognition ~~<br>

#### 12 Applications 
~~12.1 Large-Scale Deep Learning ~~<br>
~~12.2 Computer Vision ~~<br>
~~12.3 Speech Recognition ~~<br>
~~12.4 Natural Language Processing ~~<br>
~~12.5 Other Applications ~~<br>

## III Deep Learning Research 

#### 13 Linear Factor Models 
~~13.1 Probabilistic PCA and Factor Analysis ~~<br>
~~13.2 Independent Component Analysis (ICA) ~~<br>
~~13.3 Slow Feature Analysis ~~<br>
~~13.4 Sparse Coding ~~<br>
~~13.5 Manifold Interpretation of PCA ~~<br>

#### 14 Autoencoders
~~14.1 Undercomplete Autoencoders ~~<br>
~~14.2 Regularized Autoencoders ~~<br>
~~14.3 Representational Power, Layer Size and Depth ~~<br>
~~14.4 Stochastic Encoders and Decoders ~~<br>
~~14.5 Denoising Autoencoders ~~<br>
~~14.6 Learning Manifolds with Autoencoders ~~<br>
~~14.7 Contractive Autoencoders ~~<br>
~~14.8 Predictive Sparse Decomposition ~~<br>
~~14.9 Applications of Autoencoders ~~<br>

#### 15 Representation Learning 
15.1 Greedy Layer-Wise Unsupervised Pretraining <br>
15.2 Transfer Learning and Domain Adaptation <br>
15.3 Semi-Supervised Disentangling of Causal Factors <br>
15.4 Distributed Representation <br>
15.5 Exponential Gains from Depth <br>
15.6 Providing Clues to Discover Underlying Causes <br>

#### 16 Structured Probabilistic Models for Deep Learning
16.1 The Challenge of Unstructured Modeling  <br>
16.2 Using Graphs to Describe Model Structure <br>
16.3 Sampling from Graphical Models <br>
16.4 Advantages of Structured Modeling <br>
16.5 Learning about Dependencies <br>
16.6 Inference and Approximate Inference <br>
16.7 The Deep Learning Approach to StructuredProbabilistic Models <br>

#### 17 Monte Carlo Methods 
17.1 Sampling and Monte Carlo Methods <br>
17.2 Importance Sampling <br>
17.3 Markov Chain Monte Carlo Methods <br>
17.4 Gibbs Sampling <br>
17.5 The Challenge of Mixing between SeparatedModes <br>

#### 18 Confronting the Partition Function
18.1 The Log-Likelihood Gradient <br>
18.2 Stochastic Maximum Likelihood and Contrastive Divergence <br>
18.3 Pseudolikelihood <br>
18.4 Score Matching and Ratio Matching <br>
18.5 Denoising Score Matching <br>
18.6 Noise-Contrastive Estimation <br>
18.7 Estimating the Partition Function <br>

#### 19 Approximate Inference
19.1 Inference as Optimization <br>
19.2 Expectation Maximization <br>
19.3 MAP Inference and Sparse Coding <br>
19.4 Variational Inference and Learning <br>
19.5 Learned Approximate Inference <br>

#### 20 Deep Generative Models

20.1 Boltzmann Machines <br>
20.2 Restricted Boltzmann Machines <br>
20.3 Deep Belief Networks <br>
20.4 Deep Boltzmann Machines <br>
20.5 Boltzmann Machines for Real-Valued Data <br>
20.6 Convolutional Boltzmann Machines <br>
20.7 Boltzmann Machines for Structured or Sequential Outputs <br>
20.8 Other Boltzmann Machines <br>
20.9 Back-Propagation through Random Operations <br>
20.10 Directed Generative Nets <br>
20.11 Drawing Samples from Autoencoders <br>
20.12 Generative Stochastic Networks <br>
20.13 Other Generation Schemes <br>
20.14 Evaluating Generative Models <br>
20.15 Conclusion <br>

#### Bibliography

